{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "W_oI1y6-cY4d"
   },
   "source": [
    "# Assignment 1: K-Nearest Neighbors Classification (15 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "XIBjsAqjcY4e"
   },
   "source": [
    "Student Name:PRIYANKA SHIVAMPETHA\n",
    "\n",
    "Student ID:1001913"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "1Huv7ALVcY4f"
   },
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p07JVvoScY4g"
   },
   "source": [
    "#### <b>Due date</b>: Friday, 13 August 2021 5pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -10% per day (both week and weekend days counted up to 5 days)\n",
    "<ul>\n",
    "    <li>one day late, -1.5;</li>\n",
    "    <li>two days late, -3.0;</li>\n",
    "    <li>three days late, -4.5;</li>\n",
    "    <li>four days late, -6.0;</li>\n",
    "    <li>five days late, -7.5;</li>\n",
    "</ul>\n",
    "\n",
    "<b>Marks</b>: 15% of mark for class. \n",
    "\n",
    "\n",
    "<b>Materials</b>: See [Using Jupyter Notebook and Python page](https://canvas.lms.unimelb.edu.au/courses/105477/pages/python-and-jupyter-notebooks?module_item_id=2613813) on Canvas (under Modules> Coding Resources) for information on the basic setup required for this class, including an iPython notebook viewer and the python packages Numpy, Scipy, Scikit-Learn. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. We reserve the right to deduct up to 2 marks for unreadable or exessively inefficient code.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board (Piazza -> Assignment_1); we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/105477/modules\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please carefully read and fill out the <b>Authorship Declaration</b> form at the bottom of the page. Failure to fill out this form results in the following deductions: \n",
    "<UL TYPE=”square”>\n",
    "<LI>missing Authorship Declaration at the bottom of the page, -5.0\n",
    "<LI>incomplete or unsigned Authorship Declaration at the bottom of the page, -3.0\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wseHhYGScY4g"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wH9UvbJTcY4h"
   },
   "source": [
    "In this assignment, you will implement the K-nearest neighbor (KNN) classification algorithm and apply it to a real-world machine learning data set. In particular we will classify instances into seven image categories. \n",
    "\n",
    "You will read in the dataset into a feature and a label set (Q1). You will implement a preprocessing function on the feature set (Q2). You will create a train and a test set for the original as well as the processed data (Q3). You will implement different distance functions (Q4). You will implement a KNN classifier (Q5). You will apply and evaluate your classifier on the data set exploring different parameters/settings (Q6). Finally, you will critically discuss your results (Q7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Loading the data (1.5 marks)\n",
    "\n",
    "**Instructions:** For this assignment we will develop a K-Nearest Neighbors (KNN) classifier to classify image regions into pre-defined categories of outdoor spaces, namely\n",
    "```\n",
    "1: brickface\n",
    "2: sky\n",
    "3: foliage\n",
    "4: cement\n",
    "5: window\n",
    "6: path\n",
    "7: grass\n",
    "```\n",
    "\n",
    "We use a subset of the Image Segmentation data set from the UCI Machine learning repository.\n",
    "\n",
    "The original data can be found here: https://archive.ics.uci.edu/ml/datasets/image+segmentation. \n",
    "\n",
    "The dataset consists of 205 instances. Each instance corresponds to a 3x3 region of an outdoor image which has a unique identifier (the index of the instance; first field) and is characterized with 16 numeric (continuous) features named f1, f2, ..., f16.\n",
    "\n",
    "You need to first obtain this dataset, which is on Canvas (assignment 1). The files we will be using are called *segmentation.features* and *segmentation.labels*. Make sure the files are saved in the same folder as this notebook.\n",
    "\n",
    "Both files are in comma-separated value format.\n",
    "\n",
    "*segmentation.features* contains 205 instances, one instance per line. The first field is the unique instance identifier (the index). The following fields contain the 16 continuous features.\n",
    "\n",
    "*segmentation.labels* contains the gold labels (i.e., one of the seven classes above), for one instance per line. Again, the first field is the instance identifier, and the second field the instance label.\n",
    "\n",
    "**Task**: Read the two files  \n",
    "1. create a **features** set (list of features for all instances in the segmentation.* files - **Note that your feature values must not be rounded**)\n",
    "2. create a **labels** set (list of labels for all instances in the dataset). \n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* to validate your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"segmentation.features\", 'r').readlines()\n",
    "gold = open(\"segmentation.labels\", 'r').readlines()\n",
    "\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "\n",
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "###########################\n",
    "for data1 in data:\n",
    "    data1 = data1.strip()\n",
    "    data1 = data1.split(\",\")\n",
    "    inst_features1 = data1[1:]\n",
    "    inst_features1_int = []\n",
    "    for i in inst_features1:\n",
    "        inst_features1_int.append(float(i))\n",
    "    features.append(inst_features1_int)\n",
    "    \n",
    "#print(features)\n",
    "        \n",
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "###########################\n",
    "for gold1 in gold:\n",
    "    gold1 = gold1.strip()\n",
    "    gold1 = gold1.split(\",\")\n",
    "    inst_labels1 = gold1\n",
    "    inst_labels1 = gold1[1:]\n",
    "    for i in inst_labels1:\n",
    "        labels.append(int(i))\n",
    "        \n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> For your testing </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(features[0]) == len(features[-1])\n",
    "assert len(labels) == len(features)\n",
    "assert round(features[5][4],2) == 4.44 and labels[5]==6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2-A: Data Processing (1.0 marks)\n",
    "**Instructions:** Write a function that processes instances based on the range of feature values, the description below shows the data processing for feature $j$ of instance $i$:\n",
    "\n",
    "$x'_{ij}=\\frac{x_{ij}-min(x_{*j})}{max(x_{*j})-min(x_{*j})}$\n",
    "\n",
    "where $*$ denotes all possible instance identifiers. For example $x_{*1}$ is all the possible values for the first feature vector.   \n",
    "\n",
    "Your function will take as input \n",
    "- features\n",
    "\n",
    "It returns as output\n",
    "- processed features\n",
    "\n",
    "**You should implement the function from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0], [0.0, 0.5], [0.5, 1.0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "###########################\n",
    "\n",
    "def process_data(features):\n",
    "    pr_features = []\n",
    "    minmax = []\n",
    "    for i in range(len(features[0])):\n",
    "        col_values = [row[i] for row in features]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "        #return minmax\n",
    "        \n",
    "    for row in features:\n",
    "        lst =[]\n",
    "        for i in range(len(row)):\n",
    "            lst.append((row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0]))\n",
    "        pr_features.append(lst)\n",
    "\n",
    "    return pr_features \n",
    "        \n",
    "process_data([[3,5],[1,7],[2,9]])\n",
    "\n",
    "\n",
    "###########################\n",
    "## YOUR CODE ENDS HERE\n",
    "###########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> For your testing </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert process_data([[3,5],[1,7],[2,9]]) == [[1,0],[0,0.5],[0.5,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2-B: Data Processing discussion (1.0 marks)\n",
    "(a) Imagine that for feature $j$, $min(x_{*j}) = max(x_{*j})$. Would you keep this feature in your dataset? (b) Why?\n",
    "\n",
    "<b>your answer must be no more than 1-2 sentences.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-B (a). No, I wouldn't\n",
    "\n",
    "2-B (b). Because all the values will be same, and it doesn't contribute in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Train and test datasets (0.5 marks)\n",
    "\n",
    "**Task**:   \n",
    "1. create a **train_feature** set (list of features for the first 195 instances in the features), and a **train_label** set (list of labels for the corresponding).\n",
    "2. create a **test_feature** set (list of features of the remaining instances in the features) and a **test_label** set (list of labels for the corresponding). \n",
    "3. create a **pr_train_feature** set (list of processed features for the first 195 instances in the pr_features)\n",
    "4. create a **pr_test_feature** set (list of processed features of the remaining instances in the pr_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_labels   = []\n",
    "test_features = []\n",
    "test_labels   = []\n",
    "pr_train_features = []\n",
    "pr_test_features = []\n",
    "\n",
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "###########################\n",
    "\n",
    "train_features = features[:195]\n",
    "train_labels = labels[:195]\n",
    "test_features = features[195:]\n",
    "test_labels   = labels[195:]\n",
    "\n",
    "pr_features = process_data(features)\n",
    "pr_train_features = pr_features[:195]\n",
    "pr_test_features = pr_features[195:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_features) == len(train_labels)\n",
    "assert len(test_features[0])==len(test_features[-1])\n",
    "assert train_features[10][0]==0 and train_labels[10]==3\n",
    "assert len(pr_train_features) == len(train_labels)\n",
    "assert round(pr_test_features[1][2],2)== 0.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "V2OlvNAicY4i"
   },
   "source": [
    "### Question 4-A: Distance Functions (2.0 marks)\n",
    "\n",
    "<b>Instructions</b>: Implement the two distance functions specified below. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library. \n",
    "\n",
    "1. **General distance (defined below)** \n",
    "    \n",
    "    $d(x,y)=(\\sum_{i=1}^{|F|}|x_i-y_i|^p)^{1/p}$\n",
    "    \n",
    "    where $|F|$ is the number of features\n",
    "    \n",
    "Your function will take as input\n",
    "- Two feature vectors\n",
    "- Power p\n",
    "\n",
    "It returns as output\n",
    "- The distance between the two feature vectors (float)\n",
    "    \n",
    "\n",
    "2. **Cosine distance (Refer to the lecture 3 slides)**\n",
    "\n",
    "Your function will take as input \n",
    "- Two feature vectors\n",
    "\n",
    "It returns as output\n",
    "- The distance between the two feature vectors (float)\n",
    "\n",
    "**You should implement the function from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10593,
     "status": "ok",
     "timestamp": 1588139440049,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "szPlY9PIcY4j",
    "outputId": "218560c5-6e80-4a8b-bfaf-5cb46b90f34c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#########################\n",
    "# Your answer BEGINS HERE\n",
    "#########################\n",
    "   \n",
    "\n",
    "def general_distance(fv1, fv2, p):\n",
    "    # insert code here\n",
    "    summation = sum(abs(m-q)**p for m,q in zip(fv1, fv2))\n",
    "    distance  = math.pow(summation,1/p)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "general_distance([1,0],[0.5,1],3)   \n",
    "\n",
    "\n",
    "def cosine_distance(fv1, fv2):\n",
    "    # insert code here\n",
    "    sumzz, sumzk, sumkk = 0, 0, 0\n",
    "    \n",
    "    for i in range(len(fv1)):\n",
    "        z = fv1[i]\n",
    "        k = fv2[i]\n",
    "        \n",
    "        sumzz += z*z\n",
    "        sumkk += k*k\n",
    "        \n",
    "        sumzk += z*k\n",
    "    \n",
    "    return 1-(sumzk / ((math.sqrt(sumzz) * math.sqrt(sumkk))))\n",
    "\n",
    "    \n",
    "    #return distance\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# Your answer ENDS HERE\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTt3T9fycY4p"
   },
   "source": [
    "<b>For your testing: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCkSP91lcY4q"
   },
   "outputs": [],
   "source": [
    "assert round(general_distance([1,0],[0.5,1],3),2)==1.04\n",
    "assert cosine_distance([1,1,1,1], [0,1,0,0])==0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4-B: General Distance Discussion (0.5 marks)\n",
    "\n",
    "(a) What power p of general distance function will result in Euclidean distance?\n",
    "(b) What power p of general distance function will result in Manhattan distance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-B (a). p = 2 will be considered as Euclidean distance\n",
    "\n",
    "4-B (b). p = 1 will be Manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: KNN Classifier (2.0 marks)\n",
    "\n",
    "<b>Instructions</b>: Here, you implement your KNN classifier.\n",
    "\n",
    "function input \n",
    "- training data features\n",
    "- training labels \n",
    "- test data features\n",
    "- parameter K\n",
    "- distance function(s) based on which nearest neighbors will be identified\n",
    "- optional parameter for the distance functions (*args)   \n",
    "   \n",
    "\n",
    "and returns as output\n",
    "- the predicted labels for the test data\n",
    "\n",
    "**You should implement the classifier from scratch yourself**, i.e., <b> you must not</b> use an existing implementation in any Python library.\n",
    "\n",
    "**Ties among distances**. If there are more than K instances with the same (smallest) distance value, consider the first K.\n",
    "\n",
    "**Ties at prediction time.** Ties can also occur at class prediction time when two (or more) classes are supported by the same number of neighbors. You may break the ties by considering the smaller class label (if necessary). E.g., if there are the same number of nearest neighbors for both labels 1 and 3, you may select 1 as the predicted label.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## YOUR CODE BEGINS HERE\n",
    "###########################\n",
    "\n",
    "\n",
    "def distance_and_predictions(distances,k):\n",
    "    #for each test sample compute sort distances\n",
    "    #select k top distances\n",
    "    #\n",
    "    \n",
    "    \n",
    "    distances.sort(key=lambda dis: dis[1])\n",
    "    cnt = 0\n",
    "    common_items={}\n",
    "    #take k top distances and find frequncies of labels\n",
    "    #for each test sample\n",
    "    for _,tst,label in distances[:k]:                    \n",
    "        if label in common_items:\n",
    "            common_items[label] += 1\n",
    "        else:\n",
    "            common_items[label] = 1\n",
    "    mx = -1\n",
    "    curr = -1\n",
    "    #find most frequent label w.r.t to distance\n",
    "    for key,val in common_items.items():\n",
    "        if val > mx:\n",
    "            mx = val\n",
    "            curr = key\n",
    "        elif val == mx:\n",
    "            if curr > key:\n",
    "                curr = key\n",
    "    return curr\n",
    "\n",
    "\n",
    "def KNN(train_features, train_labels, test_features, k, dist_fun, *args):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    #first we compute the distances between test sample and train data\n",
    "\n",
    "    if not(len(args)):\n",
    "        for test in test_features:\n",
    "            distances = [(train_features[idx],dist_fun(test,train_features[idx]),train_labels[idx]) for idx in range(len(train_features))]\n",
    "            \n",
    "            #function to find k nearest neighbours, predictions\n",
    "            preds = distance_and_predictions(distances,k)\n",
    "            predictions.append(preds)\n",
    "    else:\n",
    "        for arg in args:    #incase args are provided\n",
    "\n",
    "            for test in test_features:\n",
    "                \n",
    "                distances = [(train_features[idx],dist_fun(test,train_features[idx],arg),train_labels[idx]) for idx in range(len(train_features))]\n",
    "                \n",
    "                #function to find k nearest neighbours, predictions\n",
    "                preds = distance_and_predictions(distances,k)\n",
    "                predictions.append(preds)\n",
    "                \n",
    "        \n",
    "    return predictions\n",
    "\n",
    "    ###########################\n",
    "    ## YOUR CODE ENDS HERE\n",
    "    ###########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWgLNH3LcY45"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert KNN([[1,1],[5,5],[1,2]], [1,0,1], [[1,1]], 1, cosine_distance) == [1]\n",
    "assert KNN([[1,1],[5,5],[1,2]], [1,0,1], [[1,1]], 1, general_distance,2) == [1]\n",
    "assert KNN([[1,1],[4,5],[1,2], [5,4]], [1,0,0,1], [[1,1]], 3, general_distance,2) == [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6-A: Applying your KNN classifiers to the Segmentation Dataset (1.5 marks)\n",
    "\n",
    "**Using the functions you have implemented in Question 4, 5 and the original train and test in Question 3, please**\n",
    "\n",
    "<b> 1. </b>\n",
    "construct four KNN classifiers with K=1, K=3, K=30, K=120. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library.  \n",
    "\n",
    "<b> Distance functions: </b>\n",
    "<ul type=\"a\">\n",
    "    <li>Euclidean distance (Use general distance in 4-A)</li>    \n",
    "    <li>Manhattan distance (Use general distance in 4-A)</li>    \n",
    "    <li>Cosine distance (Use Cosine distance in 4-A)</li>\n",
    "</ul>\n",
    "<b> Train and test data: </b> \n",
    "<ul type=\"a\">\n",
    "    <li>Original train and test (train_features and test_features)</li>     \n",
    "</ul>    \n",
    "\n",
    "You will create a total of 12 (3 distance functions x 4 K values) classifiers.\n",
    "\n",
    "<b> 2. </b>\n",
    "Compute the test accuracy for each model using the following function:\n",
    "<ul type=\"a\">\n",
    "    <li>precision_score(gold, predict, average='micro')</li>\n",
    "</ul>\n",
    "    this function returns the fraction of correct labels over all predicted labels (predict).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "0.7\n",
      "0.8\n",
      "0.6\n",
      "0.3\n",
      "Manhattan\n",
      "0.7\n",
      "0.8\n",
      "0.6\n",
      "0.3\n",
      "Cosine\n",
      "0.8\n",
      "0.9\n",
      "0.8\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# 1. Predict test labels with each KNN classifier\n",
    "\n",
    "########################\n",
    "# Your code STARTS HERE\n",
    "########################\n",
    "\n",
    "\n",
    "#knn_euc 1\n",
    "pred_knn_euc1 = KNN(train_features, train_labels, test_features, 1, general_distance,2)\n",
    "#knn_euc 3\n",
    "pred_knn_euc3 = KNN(train_features, train_labels, test_features, 3, general_distance,2)\n",
    "#knn_euc 30\n",
    "pred_knn_euc30 = KNN(train_features, train_labels, test_features, 30, general_distance,2)\n",
    "#knn_euc 120\n",
    "pred_knn_euc120 = KNN(train_features, train_labels, test_features, 120, general_distance,2)\n",
    "\n",
    "\n",
    "\n",
    "#knn_man 1\n",
    "pred_knn_man1 = KNN(train_features, train_labels, test_features, 1, general_distance,1)\n",
    "#knn_man 3\n",
    "pred_knn_man3 = KNN(train_features, train_labels, test_features, 3, general_distance,1)\n",
    "#knn_man 30\n",
    "pred_knn_man30 = KNN(train_features, train_labels, test_features, 30, general_distance,1)\n",
    "#knn_man 120\n",
    "pred_knn_man120 = KNN(train_features, train_labels, test_features, 120, general_distance,1)\n",
    "\n",
    "\n",
    "\n",
    "#knn_cos 1\n",
    "pred_knn_cos1 = KNN(train_features, train_labels, test_features, 1,  cosine_distance)\n",
    "#knn_cos 3\n",
    "pred_knn_cos3 = KNN(train_features, train_labels, test_features, 3,  cosine_distance)\n",
    "#knn_cos 30\n",
    "pred_knn_cos30 = KNN(train_features, train_labels, test_features, 30,  cosine_distance)\n",
    "#knn_cos 120\n",
    "pred_knn_cos120 = KNN(train_features, train_labels, test_features, 120, cosine_distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Compute the accuracy scores \n",
    "accuracy_knn_euc_1 = precision_score(test_labels,pred_knn_euc1,average='micro')\n",
    "accuracy_knn_euc_3 = precision_score(test_labels,pred_knn_euc3,average='micro')\n",
    "accuracy_knn_euc_30 = precision_score(test_labels,pred_knn_euc30,average='micro')\n",
    "accuracy_knn_euc_120 = precision_score(test_labels,pred_knn_euc120,average='micro')\n",
    "\n",
    "\n",
    "accuracy_knn_man_1 = precision_score(test_labels,pred_knn_man1,average='micro')\n",
    "accuracy_knn_man_3 = precision_score(test_labels,pred_knn_man3,average='micro')\n",
    "accuracy_knn_man_30 = precision_score(test_labels,pred_knn_man30,average='micro')\n",
    "accuracy_knn_man_120 = precision_score(test_labels,pred_knn_man120,average='micro')\n",
    "\n",
    "\n",
    "accuracy_knn_cos_1 = precision_score(test_labels,pred_knn_cos1,average='micro')\n",
    "accuracy_knn_cos_3 = precision_score(test_labels,pred_knn_cos3,average='micro')\n",
    "accuracy_knn_cos_30 = precision_score(test_labels,pred_knn_cos30,average='micro')\n",
    "accuracy_knn_cos_120 = precision_score(test_labels,pred_knn_cos120,average='micro')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "# Your code ENDS HERE\n",
    "########################\n",
    "\n",
    "print(\"Euclidean\")\n",
    "print(accuracy_knn_euc_1)\n",
    "print(accuracy_knn_euc_3)\n",
    "print(accuracy_knn_euc_30)\n",
    "print(accuracy_knn_euc_120)\n",
    "print(\"Manhattan\")\n",
    "print(accuracy_knn_man_1)\n",
    "print(accuracy_knn_man_3)\n",
    "print(accuracy_knn_man_30)\n",
    "print(accuracy_knn_man_120)\n",
    "print(\"Cosine\")\n",
    "print(accuracy_knn_cos_1)\n",
    "print(accuracy_knn_cos_3)\n",
    "print(accuracy_knn_cos_30)\n",
    "print(accuracy_knn_cos_120)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6-B: Applying your KNN classifiers to the processed Segmentation Dataset (1.5 marks)\n",
    "\n",
    "**Using the functions you have implemented in Question 4, 5 and the processed train and test in Question 3, please**\n",
    "\n",
    "<b> 1. </b>\n",
    "construct four KNN classifiers with K=1, K=3, K=30, K=120. Use <b>only</b> the library imported below, i.e., <b>do not</b> use implementations from any other Python library.   \n",
    "\n",
    "<b> Distance functions: </b>\n",
    "<ul type=\"a\">\n",
    "    <li>Euclidean distance (Use general distance in 4-A)</li>    \n",
    "    <li>Manhattan distance (Use general distance in 4-A)</li>    \n",
    "    <li>Cosine distance (Use Cosine distance in 4-A)</li>\n",
    "</ul>\n",
    "    \n",
    "<b> Train and test data: </b> \n",
    "<ul type=\"a\">\n",
    "    <li>Processed train and test (pr_train_features and pr_test_features)</li>\n",
    "</ul>\n",
    "    \n",
    "\n",
    "You will create a total of 12 (3 distance functions x 4 K values) classifiers.\n",
    "\n",
    "<b> 2. </b>\n",
    "Compute the test accuracy for each model using the following function:\n",
    "<ul type=\"a\">\n",
    "    <li>precision_score(gold, predict, average='micro')</li>\n",
    "</ul>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "0.8\n",
      "0.9\n",
      "0.8\n",
      "0.3\n",
      "Manhattan\n",
      "0.8\n",
      "0.9\n",
      "0.8\n",
      "0.3\n",
      "Cosine\n",
      "0.8\n",
      "0.9\n",
      "0.8\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# 1. Predict test labels with each KNN classifier\n",
    "\n",
    "########################\n",
    "# Your code STARTS HERE\n",
    "########################\n",
    "\n",
    "\n",
    "#knn_euc 1\n",
    "pred_knn_euc1 = KNN(pr_train_features, train_labels, pr_test_features, 1, general_distance,2)\n",
    "#knn_euc 3\n",
    "pred_knn_euc3 = KNN(pr_train_features, train_labels, pr_test_features, 3, general_distance,2)\n",
    "#knn_euc 30\n",
    "pred_knn_euc30 = KNN(pr_train_features, train_labels, pr_test_features, 30, general_distance,2)\n",
    "#knn_euc 120\n",
    "pred_knn_euc120 = KNN(pr_train_features, train_labels, pr_test_features, 120, general_distance,2)\n",
    "\n",
    "\n",
    "\n",
    "#knn_man 1\n",
    "pred_knn_man1 = KNN(pr_train_features, train_labels, pr_test_features, 1, general_distance,1)\n",
    "#knn_man 3\n",
    "pred_knn_man3 = KNN(pr_train_features, train_labels, pr_test_features, 3, general_distance,1)\n",
    "#knn_man 30\n",
    "pred_knn_man30 = KNN(pr_train_features, train_labels, pr_test_features, 30, general_distance,1)\n",
    "#knn_man 120\n",
    "pred_knn_man120 = KNN(pr_train_features, train_labels, pr_test_features, 120, general_distance,1)\n",
    "\n",
    "\n",
    "\n",
    "#knn_cos 1\n",
    "pred_knn_cos1 = KNN(pr_train_features, train_labels, pr_test_features, 1,  cosine_distance)\n",
    "#knn_cos 3\n",
    "pred_knn_cos3 = KNN(pr_train_features, train_labels, pr_test_features, 3,  cosine_distance)\n",
    "#knn_cos 30\n",
    "pred_knn_cos30 = KNN(pr_train_features, train_labels, pr_test_features, 30,  cosine_distance)\n",
    "#knn_cos 120\n",
    "pred_knn_cos120 = KNN(pr_train_features, train_labels, pr_test_features, 120, cosine_distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Compute the accuracy scores \n",
    "accuracy_pr_knn_euc_1 = precision_score(test_labels,pred_knn_euc1,average='micro')\n",
    "accuracy_pr_knn_euc_3 = precision_score(test_labels,pred_knn_euc3,average='micro')\n",
    "accuracy_pr_knn_euc_30 = precision_score(test_labels,pred_knn_euc30,average='micro')\n",
    "accuracy_pr_knn_euc_120 = precision_score(test_labels,pred_knn_euc120,average='micro')\n",
    "\n",
    "\n",
    "accuracy_pr_knn_man_1 = precision_score(test_labels,pred_knn_man1,average='micro')\n",
    "accuracy_pr_knn_man_3 = precision_score(test_labels,pred_knn_man3,average='micro')\n",
    "accuracy_pr_knn_man_30 = precision_score(test_labels,pred_knn_man30,average='micro')\n",
    "accuracy_pr_knn_man_120 = precision_score(test_labels,pred_knn_man120,average='micro')\n",
    "\n",
    "\n",
    "accuracy_pr_knn_cos_1 = precision_score(test_labels,pred_knn_cos1,average='micro')\n",
    "accuracy_pr_knn_cos_3 = precision_score(test_labels,pred_knn_cos3,average='micro')\n",
    "accuracy_pr_knn_cos_30 = precision_score(test_labels,pred_knn_cos30,average='micro')\n",
    "accuracy_pr_knn_cos_120 = precision_score(test_labels,pred_knn_cos120,average='micro')\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "# Your code ENDS HERE\n",
    "########################\n",
    "\n",
    "print(\"Euclidean\")\n",
    "print(accuracy_pr_knn_euc_1)\n",
    "print(accuracy_pr_knn_euc_3)\n",
    "print(accuracy_pr_knn_euc_30)\n",
    "print(accuracy_pr_knn_euc_120)\n",
    "print(\"Manhattan\")\n",
    "print(accuracy_pr_knn_man_1)\n",
    "print(accuracy_pr_knn_man_3)\n",
    "print(accuracy_pr_knn_man_30)\n",
    "print(accuracy_pr_knn_man_120)\n",
    "print(\"Cosine\")\n",
    "print(accuracy_pr_knn_cos_1)\n",
    "print(accuracy_pr_knn_cos_3)\n",
    "print(accuracy_pr_knn_cos_30)\n",
    "print(accuracy_pr_knn_cos_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Discussion (3.5 marks)\n",
    "1. (a) Which parameter K resulted in the worst performance (6-A)? (b) Why? (c) How can we remedy this problem?\n",
    "\n",
    "2. (a) How does the accuracy of KNN change by using the processed data (6-B)? (b) Which distance metrics are least and most affected by the data processing step? Why? \n",
    "\n",
    "3. Imagine a scenario where for the same segmentation dataset, instead of 7 labels, we had a binary label, i.e., 1: Window 0: Others, (a) would the accuracy measure used in Q-6 be appropriate? (b) Why?\n",
    "\n",
    "\n",
    "<b>Each question should be answered in no more than 2-3 sentences.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(a). K=120 gives worst precision score for all the distances. \n",
    "\n",
    "1(b). As we have only 195 train samples, it is very difficult for the classifier to choose the correct label,as almost every label is neighbour for test input. \n",
    "\n",
    "1(c). We can decrease size of K to overcome this problem(K=3 has best accuracy).\n",
    "\n",
    "2(a). Accuracy has improved for processed data.\n",
    "\n",
    "2(b).Most afftected are Eucledian and Manhattan as each feature has its own magnitude and distances can easily manipulated. Since processed data is scaled, every feature has same magnitude the above distances will affect. Least affected is cosine distance. Cosine distance computes angle, which doesn't affect much.\n",
    "\n",
    "3(a). No it is not appropriate. \n",
    "\n",
    "3(b). The average=\"micro\" in precision score is helpful for multiclass. For  binary classificaton problem we can set average=\"binary\"(which is by default).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Authorship Declaration</b>:\n",
    "\n",
    "   (1) I certify that the program contained in this submission is completely\n",
    "   my own individual work, except where explicitly noted by comments that\n",
    "   provide details otherwise.  I understand that work that has been developed\n",
    "   by another student, or by me in collaboration with other students,\n",
    "   or by non-students as a result of request, solicitation, or payment,\n",
    "   may not be submitted for assessment in this subject.  I understand that\n",
    "   submitting for assessment work developed by or in collaboration with\n",
    "   other students or non-students constitutes Academic Misconduct, and\n",
    "   may be penalized by mark deductions, or by other penalties determined\n",
    "   via the University of Melbourne Academic Honesty Policy, as described\n",
    "   at https://academicintegrity.unimelb.edu.au.\n",
    "\n",
    "   (2) I also certify that I have not provided a copy of this work in either\n",
    "   softcopy or hardcopy or any other form to any other student, and nor will\n",
    "   I do so until after the marks are released. I understand that providing\n",
    "   my work to other students, regardless of my intention or any undertakings\n",
    "   made to me by that other student, is also Academic Misconduct.\n",
    "\n",
    "   (3) I further understand that providing a copy of the assignment\n",
    "   specification to any form of code authoring or assignment tutoring\n",
    "   service, or drawing the attention of others to such services and code\n",
    "   that may have been made available via such a service, may be regarded\n",
    "   as Student General Misconduct (interfering with the teaching activities\n",
    "   of the University and/or inciting others to commit Academic Misconduct).\n",
    "   I understand that an allegation of Student General Misconduct may arise\n",
    "   regardless of whether or not I personally make use of such solutions\n",
    "   or sought benefit from such actions.\n",
    "\n",
    "   <b>Signed by</b>: [PRIYANKA SHIVAMPETHA ]\n",
    "   \n",
    "   <b>Dated</b>: [12/08/2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "word-similarity.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
